{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6876859",
   "metadata": {},
   "source": [
    "# Descargar datos desde un sitio web"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d1c03d",
   "metadata": {},
   "source": [
    "## Opción A — Yahoo Finance (yfinance)\n",
    "\n",
    "Pros: muy simple, sin límites estrictos; \n",
    "Contras: fuente agregada (no de un exchange específico)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7523616",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price           adj_close          close           high            low  \\\n",
      "Ticker            BTC-USD        BTC-USD        BTC-USD        BTC-USD   \n",
      "date                                                                     \n",
      "2025-09-03  111723.210938  111723.210938  112600.226562  110582.960938   \n",
      "2025-09-04  110723.601562  110723.601562  112208.328125  109347.226562   \n",
      "2025-09-05  110650.984375  110650.984375  113357.492188  110233.398438   \n",
      "2025-09-06  110224.695312  110224.695312  111275.015625  110024.085938   \n",
      "2025-09-07  111279.406250  111279.406250  111373.484375  110214.835938   \n",
      "\n",
      "Price                open       volume  \n",
      "Ticker            BTC-USD      BTC-USD  \n",
      "date                                    \n",
      "2025-09-03  111190.695312  61119643565  \n",
      "2025-09-04  111718.148438  60131132901  \n",
      "2025-09-05  110723.015625  60241647677  \n",
      "2025-09-06  110650.570312  21500719036  \n",
      "2025-09-07  110214.835938  24640706560  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# pip install yfinance pandas\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "\n",
    "# Rango 2025 completo hasta hoy\n",
    "start = \"2025-01-01\"\n",
    "end   = None  # None = hasta la fecha actual\n",
    "\n",
    "# BTC frente al USD en Yahoo Finance\n",
    "ticker = \"BTC-USD\"\n",
    "\n",
    "# Descarga de velas diarias\n",
    "btc_yahoo = yf.download(ticker, start=start, end=end, interval=\"1d\", auto_adjust=False)\n",
    "\n",
    "# Limpieza/renombrado opcional\n",
    "btc_yahoo = btc_yahoo.rename(columns={\n",
    "    \"Open\":\"open\",\"High\":\"high\",\"Low\":\"low\",\"Close\":\"close\",\"Adj Close\":\"adj_close\",\"Volume\":\"volume\"\n",
    "})\n",
    "btc_yahoo.index.name = \"date\"\n",
    "\n",
    "print(btc_yahoo.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c923562",
   "metadata": {},
   "source": [
    "## Opción B — Binance (REST público, sin API key)\n",
    "\n",
    "Pros: datos de exchange; Contras: conviene respetar rate limits.\n",
    "Descarga klines diarios (interval=1d) de BTCUSDT desde 2025-01-01 hasta hoy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93ccf6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, time, math\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "from dateutil import tz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46fd1b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       open       high        low      close  \\\n",
      "date                                                                           \n",
      "2025-09-03 23:59:59.999000+00:00  111240.01  112575.27  110528.71  111705.71   \n",
      "2025-09-04 23:59:59.999000+00:00  111705.72  112180.00  109329.12  110730.87   \n",
      "2025-09-05 23:59:59.999000+00:00  110730.87  113384.62  110206.96  110659.99   \n",
      "2025-09-06 23:59:59.999000+00:00  110660.00  111307.70  109977.00  110187.97   \n",
      "2025-09-07 23:59:59.999000+00:00  110187.98  111412.00  110180.00  111218.44   \n",
      "\n",
      "                                       volume  \n",
      "date                                           \n",
      "2025-09-03 23:59:59.999000+00:00  11773.72084  \n",
      "2025-09-04 23:59:59.999000+00:00  12203.13536  \n",
      "2025-09-05 23:59:59.999000+00:00  21587.40888  \n",
      "2025-09-06 23:59:59.999000+00:00   5000.29897  \n",
      "2025-09-07 23:59:59.999000+00:00   5032.36277  \n"
     ]
    }
   ],
   "source": [
    "# pip install requests pandas python-dateutil\n",
    "import requests, time, math\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "from dateutil import tz\n",
    "\n",
    "BASE = \"https://api.binance.com\"\n",
    "SYMBOL = \"BTCUSDT\"\n",
    "INTERVAL = \"1d\"\n",
    "LIMIT = 1000  # máximo por llamada\n",
    "\n",
    "def to_ms(dt: datetime) -> int:\n",
    "    return int(dt.timestamp() * 1000)\n",
    "\n",
    "def fetch_klines(symbol, interval, start_ms, end_ms=None, limit=1000):\n",
    "    \"\"\"\n",
    "    Descarga klines en páginas hasta cubrir [start_ms, end_ms].\n",
    "    Si end_ms es None, usa 'ahora'.\n",
    "    \"\"\"\n",
    "    if end_ms is None:\n",
    "        end_ms = to_ms(datetime.now(timezone.utc))\n",
    "\n",
    "    out = []\n",
    "    cur = start_ms\n",
    "    while cur < end_ms:\n",
    "        params = {\n",
    "            \"symbol\": symbol,\n",
    "            \"interval\": interval,\n",
    "            \"startTime\": cur,\n",
    "            \"endTime\": end_ms,\n",
    "            \"limit\": limit\n",
    "        }\n",
    "        r = requests.get(f\"{BASE}/api/v3/klines\", params=params, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        chunk = r.json()\n",
    "        if not chunk:\n",
    "            break\n",
    "        out.extend(chunk)\n",
    "        # Avanza al siguiente después del último closeTime recibido\n",
    "        last_close_ms = chunk[-1][6]\n",
    "        # Evita loops infinitos\n",
    "        next_ms = last_close_ms + 1\n",
    "        if next_ms <= cur:\n",
    "            break\n",
    "        cur = next_ms\n",
    "        # Respeta rate limits básicos\n",
    "        time.sleep(0.2)\n",
    "    return out\n",
    "\n",
    "# Fechas: desde 2025-01-01 00:00:00 UTC hasta ahora\n",
    "start_dt_utc = datetime(2025, 1, 1, 0, 0, 0, tzinfo=timezone.utc)\n",
    "start_ms = to_ms(start_dt_utc)\n",
    "end_ms = None\n",
    "\n",
    "raw = fetch_klines(SYMBOL, INTERVAL, start_ms=start_ms, end_ms=end_ms, limit=LIMIT)\n",
    "\n",
    "# Construye DataFrame\n",
    "cols = [\n",
    "    \"open_time\",\"open\",\"high\",\"low\",\"close\",\"volume\",\n",
    "    \"close_time\",\"quote_asset_volume\",\"number_of_trades\",\n",
    "    \"taker_buy_base_volume\",\"taker_buy_quote_volume\",\"ignore\"\n",
    "]\n",
    "df = pd.DataFrame(raw, columns=cols)\n",
    "\n",
    "# Tipos y tiempos\n",
    "num_cols = [\"open\",\"high\",\"low\",\"close\",\"volume\",\"quote_asset_volume\",\"taker_buy_base_volume\",\"taker_buy_quote_volume\"]\n",
    "df[num_cols] = df[num_cols].astype(float)\n",
    "\n",
    "df[\"open_time\"]  = pd.to_datetime(df[\"open_time\"], unit=\"ms\", utc=True)\n",
    "df[\"close_time\"] = pd.to_datetime(df[\"close_time\"], unit=\"ms\", utc=True)\n",
    "\n",
    "# Opcional: indexar por fecha de cierre (día de la vela)\n",
    "df = df.set_index(\"close_time\").sort_index()\n",
    "df.index.name = \"date\"\n",
    "\n",
    "# Selección de columnas OHLCV “clásicas”\n",
    "df_ohlcv = df[[\"open\",\"high\",\"low\",\"close\",\"volume\"]]\n",
    "\n",
    "print(df_ohlcv.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf339f7",
   "metadata": {},
   "source": [
    "## Pipeline robusto REST+WS a Parquet (gratuito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1055b835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestras recientes:\n",
      "                                       open       high        low      close  \\\n",
      "date                                                                           \n",
      "2025-09-03 23:59:59.999000+00:00  111240.01  112575.27  110528.71  111705.71   \n",
      "2025-09-04 23:59:59.999000+00:00  111705.72  112180.00  109329.12  110730.87   \n",
      "2025-09-05 23:59:59.999000+00:00  110730.87  113384.62  110206.96  110659.99   \n",
      "2025-09-06 23:59:59.999000+00:00  110660.00  111307.70  109977.00  110187.97   \n",
      "2025-09-07 23:59:59.999000+00:00  110187.98  111412.00  110180.00  111143.58   \n",
      "\n",
      "                                       volume  \n",
      "date                                           \n",
      "2025-09-03 23:59:59.999000+00:00  11773.72084  \n",
      "2025-09-04 23:59:59.999000+00:00  12203.13536  \n",
      "2025-09-05 23:59:59.999000+00:00  21587.40888  \n",
      "2025-09-06 23:59:59.999000+00:00   5000.29897  \n",
      "2025-09-07 23:59:59.999000+00:00   5056.35047  \n",
      "\n",
      "Guardado en: /Users/sultan/Trading/data/data/bars_curated\n",
      "Motor Parquet: No disponible (fallback CSV)\n"
     ]
    }
   ],
   "source": [
    "# === Descarga BTCUSDT 1d (Binance REST público) y guarda en Parquet particionado ===\n",
    "# Requiere: pandas, requests, tenacity y (pyarrow o fastparquet)\n",
    "# Ejecuta previamente:  python -m pip install pandas requests pyarrow fastparquet tenacity\n",
    "\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "\n",
    "# ------------------ CONFIG ------------------\n",
    "BASE    = \"https://api.binance.com\"\n",
    "SYMBOL  = \"BTCUSDT\"      # par spot\n",
    "INTERVAL= \"1d\"           # velas diarias\n",
    "LIMIT   = 1000           # máximo por llamada\n",
    "OUT     = \"data/bars_curated\"  # carpeta base de salida\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "# Motor parquet preferido (se selecciona el disponible)\n",
    "PARQUET_ENGINE = None\n",
    "try:\n",
    "    import pyarrow  # noqa\n",
    "    PARQUET_ENGINE = \"pyarrow\"\n",
    "except Exception:\n",
    "    try:\n",
    "        import fastparquet  # noqa\n",
    "        PARQUET_ENGINE = \"fastparquet\"\n",
    "    except Exception:\n",
    "        PARQUET_ENGINE = None  # se hará fallback a CSV\n",
    "\n",
    "# ------------------ HELPERS ------------------\n",
    "def to_ms(dt: datetime) -> int:\n",
    "    return int(dt.timestamp() * 1000)\n",
    "\n",
    "@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=1, max=30))\n",
    "def fetch_klines(start_ms: int, end_ms: int | None = None, limit: int = LIMIT):\n",
    "    \"\"\"Descarga páginas de klines desde start_ms hasta end_ms (o ahora si end_ms=None).\"\"\"\n",
    "    if end_ms is None:\n",
    "        end_ms = to_ms(datetime.now(timezone.utc))\n",
    "    out = []\n",
    "    cur = start_ms\n",
    "    while cur < end_ms:\n",
    "        params = {\n",
    "            \"symbol\": SYMBOL,\n",
    "            \"interval\": INTERVAL,\n",
    "            \"startTime\": cur,\n",
    "            \"endTime\": end_ms,\n",
    "            \"limit\": limit\n",
    "        }\n",
    "        r = requests.get(f\"{BASE}/api/v3/klines\", params=params, timeout=30)\n",
    "        r.raise_for_status()\n",
    "        chunk = r.json()\n",
    "        if not chunk:\n",
    "            break\n",
    "        out.extend(chunk)\n",
    "        # Avanza 1 ms después del closeTime de la última vela recibida\n",
    "        last_close_ms = chunk[-1][6]\n",
    "        nxt = last_close_ms + 1\n",
    "        if nxt <= cur:\n",
    "            break\n",
    "        cur = nxt\n",
    "        time.sleep(0.2)  # respeta rate-limits\n",
    "    return out\n",
    "\n",
    "def klines_to_df(rows: list) -> pd.DataFrame:\n",
    "    cols = [\n",
    "        \"open_time\",\"open\",\"high\",\"low\",\"close\",\"volume\",\n",
    "        \"close_time\",\"quote_asset_volume\",\"number_of_trades\",\n",
    "        \"taker_buy_base_volume\",\"taker_buy_quote_volume\",\"ignore\"\n",
    "    ]\n",
    "    df = pd.DataFrame(rows, columns=cols)\n",
    "\n",
    "    # Tipos numéricos\n",
    "    num_cols = [\"open\",\"high\",\"low\",\"close\",\"volume\",\n",
    "                \"quote_asset_volume\",\"taker_buy_base_volume\",\"taker_buy_quote_volume\"]\n",
    "    df[num_cols] = df[num_cols].astype(float)\n",
    "\n",
    "    # Tiempos\n",
    "    df[\"open_time\"]  = pd.to_datetime(df[\"open_time\"], unit=\"ms\", utc=True)\n",
    "    df[\"close_time\"] = pd.to_datetime(df[\"close_time\"], unit=\"ms\", utc=True)\n",
    "\n",
    "    # Validación básica de OHLC\n",
    "    if not (df[\"low\"] <= df[[\"open\",\"close\",\"high\"]].min(axis=1)).all():\n",
    "        raise ValueError(\"Valores de 'low' inconsistentes\")\n",
    "    if not (df[\"high\"] >= df[[\"open\",\"close\",\"low\"]].max(axis=1)).all():\n",
    "        raise ValueError(\"Valores de 'high' inconsistentes\")\n",
    "\n",
    "    # Index por cierre (día de la vela) y orden\n",
    "    df = df.sort_values(\"close_time\").drop_duplicates(subset=[\"close_time\"], keep=\"last\")\n",
    "    df = df.set_index(\"close_time\")\n",
    "    df.index.name = \"date\"\n",
    "    return df\n",
    "\n",
    "def upsert_partitioned(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Guarda por particiones year/month. Si existe, hace append + de-dup por índice (date).\n",
    "    Si no hay motor parquet disponible, hace fallback a CSV (uno por partición).\n",
    "    \"\"\"\n",
    "    # Sólo columnas que solemos usar en OHLCV (puedes ampliar)\n",
    "    keep_cols = [\"open\",\"high\",\"low\",\"close\",\"volume\",\"open_time\",\n",
    "                 \"quote_asset_volume\",\"number_of_trades\",\n",
    "                 \"taker_buy_base_volume\",\"taker_buy_quote_volume\"]\n",
    "    df = df[keep_cols]\n",
    "\n",
    "    # Particionar por año/mes del índice\n",
    "    for (y, m), chunk in df.groupby([df.index.year, df.index.month]):\n",
    "        part_dir = os.path.join(\n",
    "            OUT, f\"symbol={SYMBOL}\", f\"interval={INTERVAL}\",\n",
    "            f\"year={y:04d}\", f\"month={m:02d}\"\n",
    "        )\n",
    "        os.makedirs(part_dir, exist_ok=True)\n",
    "\n",
    "        if PARQUET_ENGINE:\n",
    "            file = os.path.join(part_dir, \"data.parquet\")\n",
    "            if os.path.exists(file):\n",
    "                old = pd.read_parquet(file)\n",
    "                # Asegura que el viejo tenga el índice 'date'\n",
    "                if old.index.name != \"date\":\n",
    "                    if \"date\" in old.columns:\n",
    "                        old = old.set_index(\"date\")\n",
    "                    else:\n",
    "                        old.index.name = \"date\"\n",
    "                merged = (\n",
    "                    pd.concat([old, chunk])\n",
    "                    .sort_index()\n",
    "                    .loc[lambda d: ~d.index.duplicated(keep=\"last\")]\n",
    "                )\n",
    "            else:\n",
    "                merged = chunk\n",
    "            merged.to_parquet(file, engine=PARQUET_ENGINE)\n",
    "        else:\n",
    "            # Fallback CSV si no hay pyarrow/fastparquet\n",
    "            file = os.path.join(part_dir, \"data.csv\")\n",
    "            if os.path.exists(file):\n",
    "                old = pd.read_csv(file, parse_dates=[\"date\"])\n",
    "                old = old.set_index(\"date\")\n",
    "                merged = (\n",
    "                    pd.concat([old, chunk])\n",
    "                    .sort_index()\n",
    "                    .loc[lambda d: ~d.index.duplicated(keep=\"last\")]\n",
    "                )\n",
    "            else:\n",
    "                merged = chunk\n",
    "            merged.to_csv(file, index=True)\n",
    "\n",
    "# ------------------ MAIN ------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Backfill desde 2025-01-01 00:00:00 UTC hasta ahora\n",
    "    start_ms = to_ms(datetime(2025, 1, 1, 0, 0, 0, tzinfo=timezone.utc))\n",
    "\n",
    "    rows = fetch_klines(start_ms=start_ms, end_ms=None, limit=LIMIT)\n",
    "    if not rows:\n",
    "        raise RuntimeError(\"No se recibieron klines del endpoint de Binance.\")\n",
    "\n",
    "    df = klines_to_df(rows)\n",
    "    upsert_partitioned(df)\n",
    "\n",
    "    # Vista rápida\n",
    "    print(\"Muestras recientes:\")\n",
    "    print(df[[\"open\",\"high\",\"low\",\"close\",\"volume\"]].tail())\n",
    "    print(f\"\\nGuardado en: {os.path.abspath(OUT)}\")\n",
    "    print(f\"Motor Parquet: {PARQUET_ENGINE if PARQUET_ENGINE else 'No disponible (fallback CSV)'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
